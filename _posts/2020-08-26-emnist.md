---
title: EMNIST
category: Papers
---

본 포스트는 2017년 IJCNN에 억셉된 EMNIST 논문을 정리한 것입니다.
[아카이브 버전](https://arxiv.org/pdf/1702.05373v1.pdf)은 [IJCNN에 억셉된 버전](https://ieeexplore.ieee.org/document/7966217)에 비해 좀 더 상세한 내용을 다루고 있어 두 페이지 모두 링크를 걸어두었습니다.
공부한 내용을 정리하는 것이기에 잘못된 점이 있을 수 있습니다.
해당 내용에 대한 교정, 첨언, 조언은 언제나 환영합니다.

## EMNIST 데이터셋이 왜 만들어졌는가?

공식적인 데이터셋은 머신러닝이 발전하는데 있어 매우 중요합니다.
알고리즘의 성능을 비교하는 기준이자 더 나은 방법을 개발하는 아이디어를 제공할 수 있기 때문입니다.
기존에 가장 많이 사용되던 데이터셋은 MNIST로 특히 컴퓨터 비전 분야에서 많이 사용되었습니다.
그러나 MNIST는 여러 방법론들에 의해 이미 거의 정복되었다고 여길 정도로 높은 분류 성능이 나왔습니다.
따라서 MNIST보다 훨씬 어려운 문제가 필요한데 이 때 고려된 것 중 하나가 NIST Special Database 19 입니다.
이 데이터셋은 원래 MNIST가 생기기 이전부터 존재한 데이터셋으로 MNIST도 이 데이터셋의 일부입니다.
만약 그 안에 있는 더 많은 데이터를 활용한다면 충분히 더 좋은 데이터셋을 만들 수 있을 것입니다.
처음 제작된 NIST 데이터셋은 현대 컴퓨팅 시스템으로 사용하기 어려운 단점이 있어 2016년에 이를 극복한 두번째 NIST 데이터셋이 공개되었습니다.
다만, 이 두번째 NIST 데이터셋은 기존의 MNIST와 직접적으로 호환되는 데이터 포멧을 가지고 있지 않습니다.
포멧을 일치시키기 위해 추가적인 변환 작업이 필요한데 여기에서 이 논문의 세가지 목표가 나타납니다.
첫번째는 NIST special database 19 데이터를 MNIST 데이터와 직접 호환, 비교할 수 있는 포멧으로 바꾸는 변환 프로세스(conversion process)를 제공하는 것입니다.
이 프로세스는 최초에 MNIST를 만들 때 사용된 방법으로 저자들은 이를 NIST 두번째 버전에 그대로 적용합니다.
그래서 새롭게 생성된 데이터셋을 확장된 MNIST(Extended Modified NIST), EMNIST라고 하며 이를 공개하는 것이 논문의 두번째 목적입니다.
추가적으로 EMNIST의 유효성을 검증하고 벤치마크 기준을 제공하는 것이 마지막 세번째 목적입니다.
EMNIST는 [이곳](https://www.westernsydney.edu.au/icns/reproducible_research/publication_support_materials/emnist)에서 다운받을 수 있습니다.

## 변환 프로세스(Conversion Process)

변환 프로세스는 NIST 데이터셋 128 x 128 이진 이미지(binary image)를 28 x 28 크기의 8-bit 회색조 이미지(gray scale)로 변환합니다.
이 변환된 이미지는 MNIST와 직접 호환이 가능한 형태입니다.
우선 전체적인 변환 과정을 논문에 있는 그림으로 확인해보겠습니다.

![](/public/img/emnist_figure1.JPG "Figure1 of emnist")

(a) 이미지는 NIST 데이터셋 128 x 128 이진 이미지(binary image)입니다.
글자의 가장자리 부분을 부드럽게 만들기 위해 $\sigma = 1$인 가우시안 필터를 적용한 결과 이미지가 (b)입니다.
글자 부분만 전체 이미지 중 사용하고 싶은 부분이므로 이 관심 영역(region of interest, ROI)만 추출한 이미지가 (c)입니다.
종횡비를 유지하며 이 글자를 이미지의 중앙에 놓는 정사각형 이미지가 생성되고 이 때 MNIST와 호환을 고려해서 1 픽셀 padding을 붙이게 되는데 이 이미지가 (d)입니다.
마지막으로 28 x 28 크기의 8-bit 회색조 이미지(gray scale)를 만들기 위해 bi-cubic interpolation 다운샘플링 방법을 사용하고 밝기값(intensity values)의 범위를 \[0, 255\]로 놓은 이미지가 (e)입니다.
이 전체적인 변환 프로세스는 MNIST와 일치하지만 ROI 추출 방법과 다운샘플링 방법에는 차이가 있습니다.
결과적으로 생성된 숫자 이미지는 기존의 MNIST와 약간 달라 이것이 얼마나 유효하게 변환된 것인지 추후 검증해볼 필요가 있습니다.

## EMNIST 데이터셋 상세

아카이브 버전과 IJCNN에 억셉된 버전을 보면 EMNIST 데이터셋이 제공하는 카테고리별 train/test 데이터셋의 수가 다릅니다.
또 아카이브 버전에는 Balanced, Digits, Letters, MNIST 카테고리가 별도로 제시되어 있는 반면 IJCNN 버전에는 이 정보가 누락되어 있습니다.
최근 많이 사용되는 딥러닝 라이브러리 pytorch와 tensorflow는 모두 아카이브 버전으로 해당 데이터셋을 제공합니다.
이 기준으로 데이터 상세 내용을 보면 다음과 같습니다.

*Split category* | *Classes* | *Training* | *Testing* | *Total* |
:---: | :---: | :---: | :---: | :---: |
byclass | 62 | 697,932 | 116,323 | 814,255 |
bymerge | 47 | 697,932 | 116,323 | 814,255 |
balanced | 47 | 112,800 | 18,800 | 131,600 |
letters | 26 | 124,800 | 20,800 | 145,600 |
digits | 10 | 240,000 | 40,000 | 280,000 |
mnist | 10 | 60,000 | 10,000 | 70,000 |

두 라이브러리에서도 letters 부분에는 차이가 있고 그 이유는 논문이 정확히 쓰여지지 않았기 때문으로 보입니다.
실제로 emnist 아카이브 논문을 보면 table 2에서 letters의 클래스 수, train/test/total 사이즈가 위의 표와 다름을 확인하실 수 있습니다.
그런데 논문의 figure 2를 보면 또다른 클래스 수, total 사이즈가 명시되어 있습니다.
논문의 내용이 일치하지 않아 라이브러리에서도 차이가 발생하고 있는 듯 합니다.
그래서 제 추측을 보태자면 letter는 모든 영어 알파벳 대소문자를 통합한 데이터셋이므로 알파벳 갯수인 26개가 클래스 수로 지정되는 것이 맞다고 생각합니다.

이외에 다른 데이터 카테고리들을 보자면 먼저 'byclass'는 모든 숫자와 모든 알파벳 대소문자를 하나의 클래스로 놓고 분류하는 문제입니다.
각 클래스별로 데이터 갯수가 달라 불균형이 심한 상태입니다.
'bymerge'는 유사한 대소문자를 하나의 카테고리로 묶은 데이터셋입니다.
예를 들어 c, o, x, z 알파벳은 대소문자의 형태가 유사합니다.
이런 데이터들을 하나로 묶어 혼란을 방지한 데이터셋이 'bymerge'며 'byclass'보다 데이터 불균형이 덜합니다.
'balanced'는 'bymerge'처럼 유사한 대소문자를 하나의 클래스로 묶되, 각 클래스별 데이터를 3,000개로 일정하게 유지한 데이터셋입니다.
데이터 수가 동일하면서 클래스 수가 많은 문제를 풀고자 한다면 이 카테고리가 적절합니다.
'digits'는 숫자 데이터만 사용한 데이터셋으로 각 클래스별 데이터가 30,000개로 균일한 데이터셋입니다.
이 데이터를 클래스당 8,000개로 줄여 기존의 MNIST와 유사한 형태로 만든 데이터셋이 'mnist' 카테고리입니다.

## 리더보드와 Baseline
EMNIST 논문은 Online Pseudo-Inverse Update Method(OPIUM)으로 학습시킨 Extreme Learning Machine(ELM)이라는 네트워크와 선형 분류기로 베이스라인 성능을 측정했습니다.
결과가 기록된 리더보드는 카테고리별로 링크를 걸어두었습니다.

- [balanced](https://paperswithcode.com/sota/image-classification-on-emnist-balanced)
- [letters](https://paperswithcode.com/sota/image-classification-on-emnist-letters)
- [digits](https://paperswithcode.com/sota/image-classification-on-emnist-digits)

성능평가분석은 앞으로 더 많이 수행되야 하지만 해당 논문에서 주로 언급되는 분류 성능에 미치는 데이터셋의 영향 중 하나는 '대소문자 분류 오류'입니다.
'bymerge' 데이터셋의 결과가 'byclass'보다 우수하게 나타나는데 그 이유로 유사한 형태를 가진 대소문자를 분류할 때 모델이 잘못 분류한 경우가 있기 때문이라고 합니다.
이 차이는 두 카테고리에서 숫자를 빼고 테스트해보면 더 두드러진다고 합니다.

이 외에도 실험 결과에서 확인해야 할 또다른 사항은 기존의 MNIST와 약간 달라진 변환 프로세스가 얼마나 유효한지 검증하는 것입니다.
논문에서는 기존의 MNIST와 EMNINST의 서브셋 MNIST를 동일한 모델로 학습시켜 그 결과가 유사하다면 유효한 변환이라고 주장합니다.
[아카이브 버전의 figure 7](https://arxiv.org/pdf/1702.05373v1.pdf)과 [IJCNN 버전의 figuer 4](https://ieeexplore.ieee.org/document/7966217)를 보면 해당 주장과 유사한 결과가 나타남을 확인할 수 있습니다.

