---
title: EMNIST
category: Papers
---

본 포스트는 2017년 IEEE에 억셉된 [EMNIST](https://ieeexplore.ieee.org/document/7966217) 논문을 정리한 것입니다.
[아카이브 버전](https://arxiv.org/pdf/1702.05373v1.pdf)은 IEEE에 억셉된 버전에 비해 좀 더 상세한 내용을 다루고 있어 두 페이지 모두 링크를 걸어두었습니다.
공부한 내용을 정리하는 것이기에 잘못된 점이 있을 수 있습니다.
해당 내용에 대한 교정, 첨언, 조언은 언제나 환영합니다.

## abstract

MNIST는 머신러닝 시스템에서 표준 벤치마크 데이터셋으로 많이 사용됩니다.
테스크가 직관적이어서 이해하기 쉽고, 저장 용량을 많이 요구하지도 않으며, 데이터베이스 자체에 접근하기도 쉽습니다.
원래 MNIST는 NIST Special Database 19라는 훨씬 큰 데이터베이스의 일부분입니다.
NIST Special Database 19는 숫자 이외에도 대소문자 데이터도 포함하고 있는 훨씬 큰 데이터셋입니다.
EMNIST(Extended MNIST) 데이터셋은 NIST 데이터셋에서 MNIST를 만들 때 사용했던 변환 프로세스를 따라 모든 NIST 데이터셋을 사용할 수 있게 만든 데이터셋입니다.
EMNIST 데이터셋은 문자와 숫자를 모두 포함하는 더 어려운 테스크를 제공하며 MNIST와 호환되는 데이터이기 때문에 기존에 MNIST를 대상으로 진행된 연구결과들을 그대로 적용해볼 수 있습니다.

## introduction

좋은 벤치마크 데이터셋은 머신러닝 분야에서 매우 중요합니다.
이 데이터를 활용해 연구자들은 여러 방법론들을 빠르고 공정하고 정량적으로 비교, 분석할 수 있으며 그 결과 알고리즘에 대한 통찰을 얻을 수 있습니다.
한 데이터셋은 일반적으로 한가지 문제만을 제공합니다.
따라서 방법론이 유용한지 알아보기 위해서는 다양한 데이터셋을 통해 알고리즘을 평가해야 합니다.
컴퓨터 비전의 분류 문제에서 많이 사용되는 데이터셋에는 **MNIST**, **CIFAR-10**, **CIFAR-100**, **STL-10**, **SVHN** 등이 있는데 이 중 MNIST가 가장 많이 사용됩니다.
이런 데이터셋들이 오랫동안 계속 의미있는 데이터셋으로 사용되려면 제공하는 문제가 충분히 더 풀 여지가 남아있어야 합니다.
그러나 안탑깝게도 MNIST는 이미 거의 최고 성능에 도달하여(레이블에 오류가 있다는 제기가 들어올 수 있을 정도) 간단한 테스트나 검증 용도로써만 사용되고 있는 실정입니다.
지금은 이런 처지이지만, MNIST가 처음 널리 사용되는 데이터셋이 된 이유는

>
> 분석에 용의한 사이즈
>
> 무료로 접근이 가능
>
> 간단히 저장하고 사용할 수 있음
>

정도를 이야기할 수 있습니다.
사실 MNIST 데이터셋은 NIST special Database 19라는 데이터셋의 일부분입니다.
NIST 데이터에는 숫자 데이터만이 아니라 문자 데이터까지 포함되어 있어 더 많은 테스크를 제공할 수 있습니다.
그러나 NIST 데이터는 현재 컴퓨팅 플랫폼에서 사용하기 어려워 이를 보완한 두 번째 버전이 2016년에 출시되었습니다.
하지만 여전히 문제가 하나 있습니다.
NIST에서 제공하는 데이터셋의 형태가 MNIST와 직접 호환되는 형태가 아닌 것입니다.
만약 이 데이터셋을 MNIST와 같은 컴퓨터 비전 문제의 데이터셋으로 활용하려면 추가적인 변환이 필요합니다.
이 논문이 제공하는 정보이자 목적은 추가적인 변환이 수행된 데이터셋을 제공하는 것입니다.
이 데이터셋을 확장된 MNIST 데이터셋(Extended Modified NIST Dataset), EMNIST라고 부를 것입니다.
해당 데이터셋은 [이곳](https://www.westernsydney.edu.au/icns/reproducible_research/publication_support_materials/emnist)에서 다운받을 수 있습니다.

>
> **MNIST 데이터셋의 히스토리**
>
> NIST v1(1995) -> MNIST(1998) -> NIST v2(2016) -> EMNIST(2017)
>

