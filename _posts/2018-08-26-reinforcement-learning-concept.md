---
layout: post
title: Reinforcement Learning Concept
category: Reinforcement Learning
---

## Meta Information
* RL Course by David Silver
* [youtube link](https://www.youtube.com/watch?v=2pWv7GOvuf0&index=1&list=PLhhVkSH_JBI8ofvmbrG7m86wmVXq_7dit) / [slide link](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/intro_RL.pdf)


2016년 알파고가 이세돌에게 4:1로 승리를 거두면서 인공지능에 대한 관심이 급속히 증가했습니다.
물론 알파고가 영화 속에서 나오는 지능을 가진 인공지능은 아닙니다.
다만, 알파고가 놀라운 이유는 불가능 속에서 가능성을 보였기 때문입니다.
바둑돌을 둘 수 있는 모든 경우의 수를 계산한다면 우주 전체 원자 수보다 많기 때문에 사실상 계산이 불가능합니다.
그렇지만 **강화학습**이라는 머신러닝 방법론을 통해 바둑두는 법을 학습한 알파고는 모든 사람들이 보는 앞에서 승리함으로써, 불가능해 보이는 계산속에서 효율적인 알고리즘을 사용하여 우리가 원하는 목적(바둑두는 방법)을 달성할 수 있음을 보여주었습니다.
이 포스트 카테고리에서는 앞으로 강화학습에 대한 이야기를 다루도록 하겠습니다.


## 강화학습이란?
간단하게 정의하자면 보상(reward)을 기반으로 학습하는 알고리즘이라고 할 수 있습니다.

> 아이가 넘어지면서 자전거 타는 법을 배우는 과정

> 레버를 누르면 치즈가 나오는 것을 배운 생쥐

사람이 어떤 행동을 하기로 결정을 내리고 그 행동 결과에 따라 옳은 행동이었는지 아니었는지를 판단하여 더 나은 결정을 하도록 지속적으로 학습하는 과정.
그것을 강화학습이라고 부를 수 있습니다.


## 강화학습의 사용분야
강화학습은 **의사결정(decision making)**이 필요한 다양한 분야에 적용될 수 있습니다.
강화학습의 컨셉이 '특정 상태에서 어떤 행동을 했을 때 향후 기대되는 보상이 최대가 될 것인가?'를 고민하는 분야이기 때문입니다.


## 강화학습 학습방법
강화학습을 학습하기 위해서 알아야하는 개념들이 있습니다.
학습의 주체가 되는 **에이전트(agent)**와 에이전트에게 상태와 보상을 알려주는 **환경(environment)**이 우선 주어져야 합니다.
에이전트는 환경과 상호작용을 통해 어떤 행동을 해야 향후 받게 될 기대보상(expected reward)이 최대가 될 수 있을지 학습합니다.
이 학습된 정보를 **정책(policy)**라고 부르게됩니다.

강화학습 알고리즘은 보상을 행동하는 즉시 받는 경우, 상당히 시간이 흐른 후에 받는 경우(delayed reward), 정책 기반으로 학습할 것인지 기대되는 가치를 어떤 방식으로 계산할 것인지, 에이전트는 하나인가 여러개인가 등 여러 조건하에서 학습방법이 다양합니다.
향후 포스팅에서 하나하나 살펴보도록 하겠습니다.
감사합니다.
